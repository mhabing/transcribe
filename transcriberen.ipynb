{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0ac3ad64-26ab-4589-be6d-79d6dbde8356",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "import re\n",
    "import xml.etree.ElementTree as ET\n",
    "from PIL import Image\n",
    "import requests\n",
    "from io import BytesIO\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "_ = load_dotenv(find_dotenv())\n",
    "\n",
    "openai.api_key  = os.getenv('OPENAI_API_KEY')\n",
    "client = openai.OpenAI()\n",
    "\n",
    "def get_completion(prompt, model=\"gpt-4\"):\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=0\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "def get_completion_text( prompt, text, model=\"gpt-4\"):\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt + \"```\" + text + \"```\"}]\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=0\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "def readtext( fname):\n",
    "    tree = ET.parse( fname)\n",
    "    root = tree.getroot()\n",
    "\n",
    "    ns = {'page': 'http://schema.primaresearch.org/PAGE/gts/pagecontent/2013-07-15'}\n",
    "    text = \"\"\n",
    "\n",
    "    for textline in root.iterfind( './/page:TextLine/page:TextEquiv[last()]/page:Unicode', ns):\n",
    "        if textline.text != None:\n",
    "            text = text + textline.text + \"\\n\"\n",
    "    return( text)\n",
    "\n",
    "def createhtml(title):\n",
    "    html = ET.Element('html')\n",
    "    head = ET.SubElement(html, 'head')\n",
    "    body = ET.SubElement(html, 'body')\n",
    "\n",
    "    title_element = ET.SubElement(head, 'title')\n",
    "    title_element.text = title\n",
    "    stylesheet = ET.SubElement(head, 'link')\n",
    "    stylesheet.set('rel', 'stylesheet')\n",
    "    stylesheet.set('href', 'style.css')\n",
    "\n",
    "    return html\n",
    "\n",
    "#splits de tekst string in coordinaten en return een array van coordinaten\n",
    "def split_coords( coords):\n",
    "    coords = coords.split( \" \")\n",
    "    list = []\n",
    "    for point in coords:\n",
    "        point = point.split( \",\")\n",
    "        list.append ( [int( point[0]), int( point[1])])\n",
    "    return list\n",
    "\n",
    "def get_boundaries( coords):\n",
    "     return( min( coords, key=lambda x: x[0])[0], min( coords, key=lambda x: x[1])[1], \n",
    "            max( coords, key=lambda x: x[0])[0], max( coords, key=lambda x: x[1])[1])\n",
    "\n",
    "def load_image( url):\n",
    "    response = requests.get( url)\n",
    "    img = Image.open( BytesIO(response.content))\n",
    "    return img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6995cbba-b783-45fb-bfde-be0429cfb148",
   "metadata": {},
   "outputs": [],
   "source": [
    "fnames = [ \n",
    " #   \"NL-HaNA_1.04.02_4994_0003-groot.xml\" , \"NL-HaNA_1.04.02_4994_0004-groot.xml\"\n",
    " #   , \"NL-HaNA_1.04.02_4994_0005-groot.xml\",\n",
    " #   \"NL-HaNA_1.04.02_4994_0006-groot.xml\"\n",
    " #   , \"NL-HaNA_1.04.02_4994_0007-groot.xml\", \"NL-HaNA_1.04.02_4994_0008-groot.xml\"\n",
    "    \"NL-HaNA_1.04.02_1098_0554-groot.xml\"\n",
    "    ]\n",
    "\n",
    "fname = fnames.last()\n",
    "html = createhtml( fname)\n",
    "body = html.find( 'body')\n",
    "\n",
    "text = \"\"\n",
    "prompt = f\"\"\"\n",
    "de tekst tussen backticks is uit een VOC brief van de 1629. Vertaal de tekst tussen drie backticks naar het Nederlands. Er kunnen\n",
    "schrijffouten in de tekst zitten. Er worden synoniemen gebruikt, bijvoorbeeld Jerommus, Jermmus Conteeles, Gerommus en Jeronius zijn \n",
    "allemaal Jeronimus Cornelisz. Namen zijn meestal geschreven als voornaam achternaam beroep. het woord Item betekent een nieuwe aanklacht.\n",
    "geef de vertaling zonder backticks of quotes.\n",
    "\"\"\"\n",
    "\n",
    "for fname in fnames:\n",
    "    text = readtext( fname)\n",
    "    response = get_completion_text( prompt, text)\n",
    "\n",
    "    ET.SubElement( body, 'h1').text = fname\n",
    "    ET.SubElement( body, 'p').text = response\n",
    "    \n",
    "\n",
    "ET.ElementTree( html).write( 'inv 1098.html')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "362ba0bb-540d-4041-ae51-7797ad6884a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(829, 255, 2975, 3886)\n"
     ]
    }
   ],
   "source": [
    "def get_word( image, coords):\n",
    "    return( image.crop( coords))\n",
    "\n",
    "fname = \"NL-HaNA_1.04.02_1098_0554-groot.xml\"\n",
    "\n",
    "ns = {'page': 'http://schema.primaresearch.org/PAGE/gts/pagecontent/2013-07-15'}\n",
    "\n",
    "tree = ET.parse( fname)\n",
    "root = tree.getroot()\n",
    "\n",
    "#read metadata from root using iterfind\n",
    "for metadata in root.iterfind( './/page:TranskribusMetadata', ns):\n",
    "        #from the metadata element, get the value of the attribute 'imgUrl'\n",
    "        url = metadata.get('imgUrl')\n",
    "        img = load_image( url)\n",
    "\n",
    "        #get the element with the coordinates of the textline\n",
    "        coordsElt = root.find( './/page:Coords', ns)\n",
    "        coords = split_coords( coordsElt.get('points'))\n",
    "        print( get_boundaries( coords))\n",
    "\n",
    "        woord = get_word( img, get_boundaries( coords))\n",
    "        woord.show()\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c23b2e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#select a region from the image\n",
    "def get_region( image, coords):\n",
    "    return( image.crop( coords))\n",
    "\n",
    "def get_rawtext( region):\n",
    "    ns = {'page': 'http://schema.primaresearch.org/PAGE/gts/pagecontent/2013-07-15'}\n",
    "    rawtext = \"\"\n",
    "    for textline in region.iterfind( './/page:TextLine/page:TextEquiv[last()]/page:Unicode', ns):\n",
    "        yield( textline) \n",
    "\n",
    "#process the text regions in the xml file\n",
    "def process_text_regions(root, prompt, dir, outfile):\n",
    "    ns = {'page': 'http://schema.primaresearch.org/PAGE/gts/pagecontent/2013-07-15'}\n",
    "    metadata = root.find( './/page:TranskribusMetadata', ns)\n",
    "    url = metadata.get('imgUrl')\n",
    "    img = load_image( url)\n",
    "\n",
    "    newhtml = createhtml( outfile)\n",
    "\n",
    "    head = newhtml.find( 'head') \n",
    "    comment = ET.Comment(prompt)\n",
    "    head.append(comment)\n",
    "\n",
    "    body = newhtml.find( 'body')\n",
    "    for region in root.iterfind( './/page:TextRegion', ns):\n",
    "#        coords = split_coords( region.find( './/page:Coords', ns).get('points'))\n",
    "#        regionimg = get_region( img, get_boundaries( coords))\n",
    "#        regionimg.save( dir + f\"region_{region.get('id')}.png\")\n",
    "#        imageref = ET.SubElement( body, 'img')\n",
    "#        imageref.attrib['src'] = f\"region_{region.get('id')}.png\"\n",
    "\n",
    "        par = ET.SubElement( body, 'ul')\n",
    "        par.text = \"\"\n",
    "        rawtext = \"\"\n",
    "        par.attrib['class'] = 'origineel'\n",
    "        for textline in get_rawtext( region):\n",
    "            if textline.text and textline.text.strip():\n",
    "                line = ET.SubElement( par, 'li')\n",
    "                line.text = textline.text\n",
    "                rawtext += textline.text + \"\\n\"\n",
    "        \n",
    "        response = get_completion_text(prompt, rawtext)\n",
    "        trans = ET.SubElement( body, 'p')\n",
    "        trans.attrib['class'] = 'transcriptie'\n",
    "        trans.text = response\n",
    "\n",
    "    ET.ElementTree( newhtml).write( dir + outfile)\n",
    "\n",
    "# Now you can call the function with root and prompt as parameters\n",
    "# process_text_regions(root, prompt)\n",
    "# \"NL-HaNA_1.04.02_4994_0004-groot.xml\",\"NL-HaNA_1.04.02_4994_0005-groot.xml\",\n",
    "filenames = [ \"NL-HaNA_1.04.02_4994_0007-groot.xml\" ]  \n",
    "\n",
    "for fname in filenames:\n",
    "    tree = ET.parse(fname)\n",
    "    root = tree.getroot()\n",
    "    with open('prompt.txt', 'r') as file:\n",
    "        prompt = file.read()\n",
    "    process_text_regions(root, prompt, './output/', fname.replace( \".xml\", \".html\"))\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "57212246",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('person', 'Jeromius Corneeles')\n",
      "('place', 'haerlem')\n",
      "('person', 'Jan Hendrickx')\n",
      "('place', 'bremen')\n",
      "('person', 'Jan hendrickx')\n",
      "('person', 'anneken heydens')\n",
      "('person', 'hans hardens')\n",
      "('person', 'hilleken herdens')\n",
      "('person', 'Hans hardensz')\n",
      "('date', '12 Julij')\n",
      "('person', 'Jeronims')\n",
      "('person', 'leendert michielsen')\n"
     ]
    }
   ],
   "source": [
    "def get_tagged_text( region):\n",
    "    ns = {'page': 'http://schema.primaresearch.org/PAGE/gts/pagecontent/2013-07-15'}\n",
    "    for textline in region.iterfind('.//page:TextLine[@custom]', ns):\n",
    "        custom = textline.get('custom')\n",
    "        rawline = textline.findall( 'page:TextEquiv[last()]/page:Unicode', ns)\n",
    "        if 'person' in custom:\n",
    "            #transform the custom attribute to a dictionary\n",
    "            tags = re.findall( r'(\\w+) \\{offset:(\\d+); length:(\\d+);\\}', custom)\n",
    "            \n",
    "            for tag in tags:\n",
    "                yield( tag[0], rawline[0].text[int(tag[1]):int(tag[1]) + int(tag[2])])\n",
    "                      \n",
    "filenames = [ \"NL-HaNA_1.04.02_4994_0007-groot.xml\" ]  \n",
    "\n",
    "for fname in filenames:\n",
    "    tree = ET.parse(fname)\n",
    "    root = tree.getroot()\n",
    "    for person in get_tagged_text( root):\n",
    "            print(person)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
